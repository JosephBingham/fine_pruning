{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import string\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data.pickle\", 'rb') as f:\n",
    "    x_train = pickle.load(f)\n",
    "    y_train = pickle.load(f)\n",
    "    batch_size = pickle.load(f)\n",
    "    x_validate = pickle.load(f)\n",
    "    y_validate = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_rows = 64\n",
    "im_cols = 32\n",
    "batch_size = batch_size\n",
    "im_shape = (im_rows, im_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = keras.models.load_model('trained_model_with_data.h5')\n",
    "cnn_copy = keras.models.load_model('trained_model_with_data.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfm\n",
    "import tempfile\n",
    "\n",
    "plm = tfm.sparsity.keras.prune_low_magnitude\n",
    "end_step = np.ceil(10/batch_size).astype(np.int32)*20\n",
    "\n",
    "pruning_params = {'pruning_schedule': tfm.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.90,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)}\n",
    "cnn_copy = keras.models.load_model('trained_model_with_data.h5')\n",
    "cnn_model = keras.models.load_model('trained_model_with_data.h5')\n",
    "\n",
    "model_for_pruning = plm(cnn_model, **pruning_params)\n",
    "\n",
    "model_for_pruning.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "i = 10\n",
    "x_fit, y_fit = x_validate[:i], y_validate[:i]\n",
    "\n",
    "callbacks = [tfm.sparsity.keras.UpdatePruningStep(), tfm.sparsity.keras.PruningSummaries(log_dir=logdir)]\n",
    "model_for_pruning.fit(x_fit, y_fit, batch_size=batch_size, epochs=5, callbacks=callbacks, verbose=0)\n",
    "s1 = model_for_pruning.evaluate(x_validate, y_validate)\n",
    "cnn_copy.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "cnn_copy.fit(x_fit, y_fit, batch_size=batch_size, epochs=10, callbacks=callbacks, verbose=0)\n",
    "s1 = model_for_pruning.evaluate(x_validate, y_validate)\n",
    "s2 = cnn_copy.evaluate(x_validate, y_validate)\n",
    "print(i)\n",
    "print(s0)\n",
    "print()\n",
    "print(s1)\n",
    "print()\n",
    "print(s2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
